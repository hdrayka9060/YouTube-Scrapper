{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c491e3",
      "metadata": {
        "id": "09c491e3"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-driver\n",
        "!apt install -y chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KKY1jNu4Y6lj"
      },
      "id": "KKY1jNu4Y6lj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    # options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    # options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    # driver = webdriver.Chrome(executable_path='/usr/lib/chromium-browser/chromedriver',options=options)\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver"
      ],
      "metadata": {
        "id": "clrKH4tkY7av"
      },
      "id": "clrKH4tkY7av",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e917ca",
      "metadata": {
        "id": "b7e917ca"
      },
      "outputs": [],
      "source": [
        "# reading csv\n",
        "df=pd.read_csv(\"/content/drive/My Drive/data_2023-10-27_11-06-43.csv\")\n",
        "\n",
        "# changing data-types of columns to string\n",
        "df['Source']=df['Source'].astype('string')\n",
        "df['Published'] = df['Published'].astype('string')\n",
        "df['Title'] = df['Title'].astype('string')\n",
        "df['Link'] = df['Link'].astype('string')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efff8cfc",
      "metadata": {
        "id": "efff8cfc"
      },
      "outputs": [],
      "source": [
        "# function to remove extra spaces from string\n",
        "def remove_extra_spaces(text):\n",
        "    new_text = re.sub(r'\\s+', '+', text)\n",
        "    new_text = new_text.strip()\n",
        "    return new_text+'+news'\n",
        "\n",
        "# function to trim string\n",
        "def trim(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "# function to format date\n",
        "def idate(date):\n",
        "    mon={'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06','Jul':'07','Aug':'08','Sep':'09','Oct':'10','Nov':'11','Dec':'12'}\n",
        "    if date[-1]==' ':\n",
        "        return date[-5:-1]+'-'+mon[date[2:5]]+'-0'+date[:1]\n",
        "    return date[-4:]+'-'+mon[date[3:6]]+'-'+date[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a17030",
      "metadata": {
        "id": "78a17030"
      },
      "outputs": [],
      "source": [
        "# Creating Search Term(search_term) and Date(idate) columns having proper format to search and compare date on YouTube\n",
        "# Search term is fromed by replacing space by '+' in title\n",
        "\n",
        "search_term=[]\n",
        "add_date=[]\n",
        "for i in range(len(df)):\n",
        "    search_term.append(remove_extra_spaces(df['Title'][i]))\n",
        "    if len(df[\"Published\"][i])==0:\n",
        "        add_date.append(\"0000-00-00\")\n",
        "    elif df[\"Published\"][i][4]=='-':\n",
        "        add_date.append(df[\"Published\"][i][:10])\n",
        "    elif df[\"Published\"][i][2]=='-':\n",
        "        add_date.append(df[\"Published\"][i][6:10]+'-'+df[\"Published\"][i][3:5]+'-'+df[\"Published\"][i][:2])\n",
        "    else:\n",
        "        add_date.append(idate(df[\"Published\"][i][5:16]))\n",
        "df['search_term']=search_term\n",
        "df['idate']=add_date\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb103eb",
      "metadata": {
        "id": "8eb103eb"
      },
      "outputs": [],
      "source": [
        "#function to get date\n",
        "def gdate(date):\n",
        "    mon={'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06','Jul':'07','Aug':'08','Sep':'09','Oct':'10','Nov':'11','Dec':'12'}\n",
        "\n",
        "    if len(date)==11:\n",
        "        return date[-4:]+'-'+mon[date[:3]]+'-'+date[4:5]\n",
        "\n",
        "    return date[-4:]+'-'+mon[date[:3]]+'-'+date[4:6]\n",
        "\n",
        "#function to get views\n",
        "def gviews(views):\n",
        "    s=\"\"\n",
        "    for i in views:\n",
        "        if i>='0' and i<='9':\n",
        "            s+=i\n",
        "    return int(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc2a5d5",
      "metadata": {
        "id": "1dc2a5d5"
      },
      "outputs": [],
      "source": [
        "# Controling browser from selinium\n",
        "browser=web_driver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d638cb7",
      "metadata": {
        "id": "4d638cb7"
      },
      "outputs": [],
      "source": [
        "# Scrapping Views from Youtube\n",
        "\n",
        "# Explanation of Method Used\n",
        "# In this part we are searching top videos for title of articles and comparing their upload date with published date of article\n",
        "# If upload date of video is within fews days(10 days) of publish date of article then that video is selected\n",
        "# Max views from selected videos is considered and stored\n",
        "\n",
        "views=[]                              # list to store views\n",
        "for k in range(0,100):               # Iterating for first 100 rows\n",
        "\n",
        "    v=-1\n",
        "    browser.get(f\"https://www.youtube.com/results?search_query={df['search_term'][k]}\")          # Searching the title of article on youtube\n",
        "    time.sleep(3)                                                                                # waiting to load the page\n",
        "    ele = browser.find_elements(By.XPATH, '//div[@id=\"contents\"]/ytd-video-renderer/div[@id=\"dismissible\"]/ytd-thumbnail')  # Catching / Handleing videos from searchh results\n",
        "    cnt=0\n",
        "\n",
        "    for i in ele:    # Iterating the videos\n",
        "\n",
        "        if cnt>=10:  # breaking at 10th video\n",
        "            break\n",
        "        cnt=cnt+1\n",
        "\n",
        "        try:\n",
        "            i.click()            # Cicking the videos\n",
        "            time.sleep(1)        # waiting to load the video\n",
        "\n",
        "            try:\n",
        "                desc=browser.find_element(By.XPATH, '//div[@id=\"info-container\"]/yt-formatted-string/span')  # Finding Description of video\n",
        "                desc.click()\n",
        "                time.sleep(1)\n",
        "\n",
        "                pcont1=browser.find_elements(By.ID,\"info-container\")\n",
        "                pcont2=pcont1[0].find_elements(By.ID,'info')\n",
        "                pcont3=pcont2[0].find_elements(By.TAG_NAME,'span')\n",
        "\n",
        "                viu=gviews(pcont3[0].text[:-6])                            # Scraping views of video\n",
        "                dat1=gdate(pcont3[2].text)                                 # Scraping date of upload of video\n",
        "                dat2=df[\"idate\"][k]\n",
        "\n",
        "                cdate1 = datetime.strptime(dat1, \"%Y-%m-%d\")\n",
        "                cdate2 = datetime.strptime(dat2, \"%Y-%m-%d\")\n",
        "                ddiff=cdate1-cdate2\n",
        "                ddiff=ddiff.days\n",
        "\n",
        "                if ddiff>=-10 and ddiff <=10 and viu>v:                   # Comparing date of upload of video with published date of article\n",
        "                    v=viu\n",
        "\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            browser.back()                                               # Back to previous page of searchh results\n",
        "            time.sleep(1)\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    views.append(v)\n",
        "    print(k,v)\n",
        "\n",
        "print(views)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb46375",
      "metadata": {
        "id": "ffb46375"
      },
      "outputs": [],
      "source": [
        "# Saving views to csv\n",
        "# df2=pd.DataFrame(views)\n",
        "# df2.to_csv('Yt_Views_Scrapping_4-4.5_csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}